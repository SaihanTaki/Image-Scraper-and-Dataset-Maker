{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What do you want to download? cat\n",
      "How many images? 60\n",
      "Label of the image? 1\n",
      "Opening the browser...\n",
      "Scrolling the web page...\n",
      "Scrolling End!\n",
      "Browser Closed!\n",
      "Start downloading.....\n",
      "Download finished!\n",
      "55 image downloaded.\n",
      "Time elapsed 42.68992042541504 seconds\n",
      "Dataset Created!\n",
      "Image_directory is not deleted!\n",
      " ---------------------------------------\n",
      "                                    Info:\n",
      "                                    ---------------------------------------\n",
      "                                    Data : {0: 'car', 1: 'cat'}\n",
      "                                    Training set length : 82\n",
      "                                    Test set length : 20\n",
      "                                    Folders in the directory : ['labels.csv', 'test', 'test_labels.csv', 'train']\n",
      "                                    ---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "################################ Import Packages################################################\n",
    "\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import requests\n",
    "import shutil\n",
    "import random\n",
    "import math\n",
    "import uuid\n",
    "import time\n",
    "import os\n",
    "\n",
    "\n",
    "##################################################################################################\n",
    "######################################## Scraping Image ##########################################\n",
    "##################################################################################################\n",
    "\n",
    "def scroll_webpage(driver, n_images):\n",
    "\n",
    "    print(\"Scrolling the web page...\")\n",
    "\n",
    "    if n_images > 20:\n",
    "\n",
    "        i = 0\n",
    "        while i < 5:\n",
    "            # for scrolling page\n",
    "            driver.execute_script(\n",
    "                \"window.scrollBy(0,document.body.scrollHeight)\")\n",
    "\n",
    "            try:\n",
    "                # for clicking show more results button\n",
    "                driver.find_element_by_xpath(\n",
    "                    \"/html/body/div[2]/c-wiz/div[3]/div[1]/div/div/div/div/div[5]/input\").click()\n",
    "            except Exception as e:\n",
    "                pass\n",
    "\n",
    "            time.sleep(5)\n",
    "            i += 1\n",
    "\n",
    "    else:\n",
    "        driver.execute_script(\"window.scrollBy(0,document.body.scrollHeight)\")\n",
    "\n",
    "    print(\"Scrolling End!\")\n",
    "\n",
    "    return None\n",
    "\n",
    "############################################################################################\n",
    "\n",
    "\n",
    "def scrap_images(url, n_images, driver_path):\n",
    "\n",
    "    driver = webdriver.Chrome(driver_path)\n",
    "\n",
    "    print(\"Opening the browser...\")\n",
    "    driver.get(url)\n",
    "\n",
    "    scroll_webpage(driver, n_images)\n",
    "    # Parsing\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    # Close the driver\n",
    "    driver.close()\n",
    "    print(\"Browser Closed!\")\n",
    "\n",
    "    img_tags = soup.find_all(\"img\", class_=\"rg_i\", limit=n_images)\n",
    "    #imgs = soup.select('img[src^=\"data:image/jpeg\"]')\n",
    "\n",
    "    return img_tags\n",
    "\n",
    "##########################################################################################################\n",
    "\n",
    "\n",
    "def download_images(img_tags, save_directory):\n",
    "\n",
    "    # Check the directory\n",
    "    if not os.path.exists(save_directory):\n",
    "        os.mkdir(save_directory)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    # Downloading iamges\n",
    "    print(\"Start downloading.....\")\n",
    "\n",
    "    for img in img_tags:\n",
    "\n",
    "        path1 = save_directory\n",
    "\n",
    "        try:\n",
    "            name = str(uuid.uuid4())\n",
    "            path2 = name+\".jpg\"\n",
    "            file_path = os.path.join(path1, path2)\n",
    "            urllib.request.urlretrieve(img['src'], file_path)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # Check the number of downloaded image\n",
    "    n_downloded_image = len(os.listdir(save_directory))\n",
    "\n",
    "    print(\"Download finished!\")\n",
    "    print(\"{} image downloaded.\".format(n_downloded_image))\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "####################################################################################################\n",
    "###################################### Creating Dataset ############################################\n",
    "####################################################################################################\n",
    "\n",
    "def train_labels_csv(dataset_directory, image_name, label):\n",
    "\n",
    "    label = str(label)\n",
    "\n",
    "    file_path = os.path.join(dataset_directory, \"labels.csv\")\n",
    "    train_directory = os.path.join(dataset_directory,\"train\",image_name)\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        with open(file_path, \"w\") as f:\n",
    "\n",
    "            header = \"Image\"+\",\"+\"Label\"+\"\\n\"\n",
    "            f.write(header)\n",
    "            \n",
    "            image_list = os.listdir(train_directory)\n",
    "            \n",
    "            for img in image_list:\n",
    "                single_row = img+\",\"+label+\"\\n\"\n",
    "                f.write(single_row)\n",
    "                \n",
    "    else:\n",
    "        with open(file_path, \"a\") as f:\n",
    "            \n",
    "            image_list = os.listdir(train_directory)\n",
    "            \n",
    "            for img in image_list:\n",
    "                single_row = img+\",\"+label+\"\\n\"\n",
    "                f.write(single_row)\n",
    "        \n",
    "            \n",
    "    shuffle_csv_dataset(file_path)\n",
    "\n",
    "    return None\n",
    "\n",
    "############################################################################################################\n",
    "\n",
    "\n",
    "def test_labels_csv(dataset_directory, image_name, label):\n",
    "\n",
    "    label = str(label)\n",
    "\n",
    "    file_path = os.path.join(dataset_directory, \"test_labels.csv\")\n",
    "    test_directory = os.path.join(dataset_directory,\"test\",image_name)\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        with open(file_path, \"w\") as f:\n",
    "\n",
    "            header = \"Image\"+\",\"+\"Label\"+\"\\n\"\n",
    "            f.write(header)\n",
    "            \n",
    "            image_list = os.listdir(test_directory)\n",
    "            \n",
    "            for img in image_list:\n",
    "                single_row = img+\",\"+label+\"\\n\"\n",
    "                f.write(single_row)\n",
    "                \n",
    "    else:\n",
    "        with open(file_path, \"a\") as f:\n",
    "            \n",
    "            image_list = os.listdir(test_directory)\n",
    "            \n",
    "            for img in image_list:\n",
    "                single_row = img+\",\"+label+\"\\n\"\n",
    "                f.write(single_row)\n",
    "        \n",
    "            \n",
    "    shuffle_csv_dataset(file_path)\n",
    "\n",
    "    return None\n",
    "\n",
    "############################################################################################################\n",
    "\n",
    "\n",
    "def shuffle_csv_dataset(file_path,seed=42):\n",
    "\n",
    "    random.seed(seed)\n",
    "    \n",
    "    with open(file_path,\"r\") as f:\n",
    "        lines= f.readlines()\n",
    "        header = lines[0]\n",
    "        rows = lines[1:]\n",
    "    \n",
    "    with open(file_path,\"w\") as f:\n",
    "        f.write(header)\n",
    "        random.shuffle(rows)\n",
    "        for line in rows:\n",
    "            f.write(line)\n",
    "    \n",
    "    return None\n",
    "\n",
    "############################################################################################################\n",
    "\n",
    "\n",
    "def train_test_split(data_directory, split=0.8, seed=42):\n",
    "\n",
    "    random.seed(seed)\n",
    "\n",
    "    image_list = os.listdir(data_directory)\n",
    "    random.shuffle(image_list)\n",
    "\n",
    "    dataset_length = len(image_list)\n",
    "    train_length = math.ceil(len(image_list)*split)\n",
    "    test_length = len(image_list) - train_length\n",
    "\n",
    "    train = []\n",
    "    test = []\n",
    "\n",
    "    for i in range(train_length):\n",
    "        train.append(image_list[i])\n",
    "\n",
    "    for i in range(train_length, dataset_length):\n",
    "        test.append(image_list[i])\n",
    "\n",
    "    return train, test\n",
    "\n",
    "##################################################################################################\n",
    "\n",
    "\n",
    "def make_dataset(dataset_directory, image_directory, image_name, split=0.8, seed=42):\n",
    "\n",
    "    train_path = os.path.join(dataset_directory, \"train\", image_name)\n",
    "    test_path = os.path.join(dataset_directory, \"test\", image_name)\n",
    "\n",
    "    paths = [train_path, test_path]\n",
    "\n",
    "    for path in paths:\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    train, test = train_test_split(image_directory, split, seed)\n",
    "\n",
    "    for image in train:\n",
    "        path = os.path.join(train_path, image)\n",
    "        with open(image_directory+\"/\"+image, 'rb') as f:\n",
    "            img = f.read()\n",
    "            with open(path, \"wb\") as f:\n",
    "                f.write(img)\n",
    "\n",
    "    for image in test:\n",
    "        path = os.path.join(test_path, image)\n",
    "        with open(image_directory+\"/\"+image, 'rb') as f:\n",
    "            img = f.read()\n",
    "            with open(path, \"wb\") as f:\n",
    "                f.write(img)\n",
    "\n",
    "    return None\n",
    "\n",
    "##########################################################################################################\n",
    "\n",
    "\n",
    "def dataset_information(dataset_directory):\n",
    "    \n",
    "    folders = os.listdir(dataset_directory)\n",
    "    \n",
    "    file_path_train = os.path.join(dataset_directory,\"labels.csv\")\n",
    "    with open(file_path_train,\"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        rows = lines[1:]\n",
    "        train_len = len(rows)\n",
    "        \n",
    "    file_path_test = os.path.join(dataset_directory,\"test_labels.csv\")\n",
    "    with open(file_path_test,\"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        rows = lines[1:]\n",
    "        test_len = len(rows)\n",
    "        \n",
    "    \n",
    "    train_path = os.path.join(dataset_directory,\"train\") \n",
    "    data = {}\n",
    "    for idx,img_name in enumerate(os.listdir(train_path)):\n",
    "        data[idx] = img_name\n",
    "        \n",
    "    Information = Information = ''' ---------------------------------------\n",
    "                                    Info:\n",
    "                                    ---------------------------------------\n",
    "                                    Data : {}\n",
    "                                    Training set length : {}\n",
    "                                    Test set length : {}\n",
    "                                    Folders in the directory : {}\n",
    "                                    ---------------------------------------'''.format( data, train_len, test_len, folders)\n",
    "    \n",
    "    return Information\n",
    "\n",
    "##########################################################################################################\n",
    "\n",
    "\n",
    "def main(dataset=False,del_img_dir=False,dataset_info=True):\n",
    "\n",
    "    image_name = input(\"What do you want to download? \")\n",
    "    n_images = int(input(\"How many images? \"))\n",
    "    label = int(input(\"Label of the image? \"))\n",
    "    url = 'https://www.google.com/search?tbm=isch&q='+image_name\n",
    "    driver_path = \"readonly/chromedriver.exe\"\n",
    "    image_directory = \"readonly/images\"+\"_\"+image_name\n",
    "    dataset_directory = \"readonly/Data_Set\"\n",
    "    \n",
    "    tic = time.time()\n",
    "    \n",
    "    img_tags = scrap_images(url, n_images, driver_path)\n",
    "\n",
    "    download_images(img_tags=img_tags, save_directory=image_directory)\n",
    "    \n",
    "    toc = time.time()\n",
    "    \n",
    "    elapsed_time = toc-tic\n",
    "    \n",
    "    print(\"Time elapsed {} seconds\".format(elapsed_time))\n",
    "    \n",
    "\n",
    "    if dataset:\n",
    "        make_dataset(dataset_directory, image_directory, image_name)\n",
    "        train_labels_csv(dataset_directory, image_name, label)\n",
    "        test_labels_csv(dataset_directory, image_name, label)\n",
    "        print(\"Dataset Created!\")\n",
    "    else:\n",
    "        print(\"Dataset is not created!\")\n",
    "    \n",
    "    if del_img_dir:\n",
    "        try:\n",
    "            shutil.rmtree(image_directory)\n",
    "            print(\"Image_directory is deleted!\")\n",
    "        except:\n",
    "            pass\n",
    "    else:\n",
    "        print(\"Image_directory is not deleted!\")\n",
    "        \n",
    "    \n",
    "    if dataset_info:\n",
    "        information = dataset_information(dataset_directory)\n",
    "        print(information)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    return None\n",
    "\n",
    "#############################################################################################################\n",
    "#############################################################################################################\n",
    "#############################################################################################################\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    main(dataset=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
